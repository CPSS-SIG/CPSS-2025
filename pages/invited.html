<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

#INCLUDE# head.html

<body>
#INCLUDE# title.html

#INCLUDE# navigation.html




<div id="contents">

<h1>Invited Talk</h1>
<div class="text">
	<p> We are excited to announce that <b><font color="#821019">Paul Röttger</font></b> and <b><font color="#821019">Qixiang Fang</font></b> have accepted our invitation to give a keynote talk at CPSS!</p>
  
  <br/><br/>
  </div><br/>
   

<h3>Paul Röttger</h3>  
<div class="keynote">
  <div class="image">
    <a href="https://paulrottger.com"><img src="paul.png" alt="Picture of Paul Röttger" width="150"></a>
  </div>  

  <div class="text">
    <h1>Measuring Political Bias in Large Language Models</h1>

    <p>Large language models (LLMs) are helping millions of users to learn and write about a diversity of issues. In doing so, LLMs may expose users to new ideas and perspectives, or reinforce existing knowledge and user opinions. This creates concerns about political bias in LLMs, and how such bias might influence LLM users and society. In my talk, I will discuss why measuring political bias in LLMs is difficult, and why we should be skeptical about most evidence so far. Then, I will present our approach to building a more meaningful evaluation dataset called IssueBench, to measure biases in how LLMs write about political issues. I will describe the steps we took to make IssueBench realistic and robust. Then, I will outline our results from testing state-of-the-art LLMs with IssueBench, including clear evidence for issue bias, striking similarities in biases across models, and strong alignment with Democrat over Republican voter positions on a subset of issues.</p>
 
    <h1>Bio</h1>
    <p>Paul is a postdoctoral researcher in the MilaNLP Lab at Bocconi University, working on evaluating and improving the alignment and safety of large language models, as well as measuring their societal impacts. For his recent work in this area, he won Outstanding Paper at ACL and Best Paper at NeurIPS D&B. Before coming to Milan, Paul completed his PhD at the University of Oxford, where he worked on LLMs for hate speech detection. During his PhD, Paul also co-founded a start-up building AI for content moderation, which was acquired by another large online safety company in 2023.</p>
    <br> <br>  
    </div>
  </div>

  <h3>Qixiang Fang</h3>

  <div class="keynote">
    <div class="image">
      <a href="https://www.uu.nl/staff/QFang"><img src="qixiang2.jpeg" alt="Picture of Qixiang Fang" width="150"></a>
    </div>  

  <div class="text">
    <h1>tba</h1> 
	<p>
	</p>

    <h1>Bio</h1>
    <p>
    </p>
        <br/><br/>  
  </div>
</div>
</div>

<div id="footer">
  <div class="clearfix">
    <p>
      The 5th Workshop on Computational Linguistics for the Political and Social Sciences (CPSS)
      &emsp;&emsp;&emsp;&emsp;
      Contact: <a href="mailto:">rehbein@uni-mannheim.de</a>.<br>

  </div>
</div>

</body>
</html>
