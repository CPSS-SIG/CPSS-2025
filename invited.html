<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <title>CPSS-2025 </title>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300%7CRoboto:300%7CSlabo+27px" rel="stylesheet">
    <link rel="stylesheet" href="cpss2025.css" type="text/css"/>
    <link rel="icon" type="image/png" href="logo_cpss.jpg" sizes="120x120">

</head>

<body>
<div id="header">
  <table>
    <tr valign="bottom">
      <td><img src="logo_cpss.jpg" /></td>
      <td>
	      <p class="title">The 5th Workshop on Computational Linguistics<br/><br/> for the Political and Social Sciences (CPSS)</p>
        <!-- update workshop location as required -->
        <p class="body">Co-located with KONVENS 2025 in Hildesheim, Germany  &ndash; Sep 2025</p>
      </td>
    </tr>
  </table>
</div>


<div id="subheader">
	<ul id="navigation">
		<li><a href="index.html">Home</a></li>
		<li><a href="cfp.html">Call for Papers</a></li>
		<!--li><a href="submission.html">Submission</a></li-->
		<li><a href="program.html">Program</a></li>
		<li><a href="accepted.html">Accepted Papers</a>
		<li class="active"><a href="invited.html">Invited Talk</a></li>
		<li><a href="committee.html">Committees</a></li>
		<!-- <li><a href="dinner.html">Workshop Dinner</a></li> -->
	</ul>
</div>




<div id="contents">

<h1>Invited Talk</h1>
<div class="text">
	<p> We are excited to announce that <b><font color="#821019">Paul Röttger</font></b> and <b><font color="#821019">Qixiang Fang</font></b> have accepted our invitation to give a keynote talk at CPSS!</p>
  
  <br/><br/>
  </div><br/>
   

<h3>Paul Röttger (MilaNLP Lab at Bocconi University)</h3>  
<div class="keynote">
  <div class="image">
    <a href="https://paulrottger.com"><img src="paul.png" alt="Picture of Paul Röttger" width="150"></a>
  </div>  

  <div class="text">
    <h1>Measuring Political Bias in Large Language Models</h1>

    <p>Large language models (LLMs) are helping millions of users to learn and write about a diversity of issues. In doing so, LLMs may expose users to new ideas and perspectives, or reinforce existing knowledge and user opinions. This creates concerns about political bias in LLMs, and how such bias might influence LLM users and society. In my talk, I will discuss why measuring political bias in LLMs is difficult, and why we should be skeptical about most evidence so far. Then, I will present our approach to building a more meaningful evaluation dataset called IssueBench, to measure biases in how LLMs write about political issues. I will describe the steps we took to make IssueBench realistic and robust. Then, I will outline our results from testing state-of-the-art LLMs with IssueBench, including clear evidence for issue bias, striking similarities in biases across models, and strong alignment with Democrat over Republican voter positions on a subset of issues.</p>
 
    <h1>Bio</h1>
    <p>Paul is a postdoctoral researcher in the MilaNLP Lab at Bocconi University, working on evaluating and improving the alignment and safety of large language models, as well as measuring their societal impacts. For his recent work in this area, he won Outstanding Paper at ACL and Best Paper at NeurIPS D&B. Before coming to Milan, Paul completed his PhD at the University of Oxford, where he worked on LLMs for hate speech detection. During his PhD, Paul also co-founded a start-up building AI for content moderation, which was acquired by another large online safety company in 2023.</p>
    <br> <br>  
    </div>
  </div>

  <h3>Qixiang Fang (ODISSEI Social Data Science (SoDa) Team<br/><br/> at Utrecht University)</h3>

  <div class="keynote">
    <div class="image">
      <a href="https://www.uu.nl/staff/QFang"><img src="qixiang2.jpeg" alt="Picture of Qixiang Fang" width="150"></a>
    </div>  

  <div class="text">
	  <h1>From Psychometrics to Practice:<br/><br/> Validating NLP for Political and Social Research</h1> 
	<p>The growing use of NLP in political and social science offers exciting opportunities, but also raises concerns about validity, reproducibility, and bias. In this talk, I discuss how psychometric principles can strengthen the evaluation of text-based measures, from construct validity in embeddings to benchmarking large language models with the PATCH framework. I also highlight challenges in reproducibility, showing how common flaws in human evaluation undermine trust in findings, and I reflect on the ethical risks of emerging applications such as personality inference. Building on these insights, I propose best practices to align NLP with social science standards. By integrating psychometric rigor with computational methods, we can make NLP a more reliable tool for understanding political and social phenomena.
	</p>

    <h1>Bio</h1>
    <p>Qixiang Fang is a postdoctoral researcher at Utrecht University and a senior member of the <a href="https://odissei-soda.nl/">ODISSEI SoDa Team</a>. He advises social science and humanities researchers in the Netherlands on integrating NLP and other computational methods into their work. He organizes a recurring <a href="https://sodascience.github.io/workshop_llm_data_collection/">workshop on using large language models for data collection and on addressing measurement error in LLM-generated labels for downstream modeling</a>. He obtained his PhD at Utrecht University, where his research explored how measurement theory can strengthen the application of NLP in the social sciences and humanities.
    </p>
        <br/><br/>  
  </div>
</div>
</div>

<div id="footer">
  <div class="clearfix">
    <p>
      The 5th Workshop on Computational Linguistics for the Political and Social Sciences (CPSS)
      &emsp;&emsp;&emsp;&emsp;
      Contact: <a href="mailto:">rehbein@uni-mannheim.de</a>.<br>

  </div>
</div>

</body>
</html>
